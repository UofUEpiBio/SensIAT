---
title: "Simulation of Integral Equivalency"
author: "Andrew Redd"
format: 
    html:
        standalone: true
        self-contained: true
editor: visual
---

```{r}
devtools::load_all('.')
```

## Introduction

This document will show that the numerical and exact computation of the integral for term 2 of the influence function are equal. The integral of interest is

$$
\int_{t=a}^b V^{-1}B(t)\hat{E}[Y(t)|\bar{O}(t)_i]dt
$$

Which reduces to

$$
\int^b_{t=a} V^{-1}B(t) \frac{    \sum_{j=1}^N Y_j e^{\alpha Y_j}\kappa(\beta X_j - \beta x_i(t)|h))}{    \sum_{j=1}^N e^{\alpha Y_j}\kappa(\beta X_j - \beta x_i(t)|h))}dt
$$

For this I will use the example of the ARC data. We will be working with the common knots. Similar to previously but adjusted to have the knots on the boundaries of the interval $[60,460]$ as is needed for the exact computations to be identical.

```{r}
library(tidyverse)
a <- 60
b <- 460
knots <- c(rep(a, 4),(a+b)/2,rep(b, 4))
source("../R/spline_fn.R")
alpha <- c(-0.3, 0, 0.3)
```

First we will show that the spline basis functions from the package `orthogonalsplinebasis` are equivalent to the original.

```{r}
library(orthogonalsplinebasis)
base <- SplineBasis(knots)

eval.points <- seq(60, 460, length.out=1000)

orig <- sapply(eval.points, spline_fn, knots)

new. <- evaluate(base, eval.points)

all.equal(t(orig), new.)
```

Next we will show that the exact version of the Gram matrix is equal to the numerically approximated version. In all numerical approximation we will use the trapezoidal approximation, although that is not what was used in the original paper, it is numerically more accurate.

```{r}
delta <- diff(head(eval.points,2))
V.orig <- (crossprod(head(t(orig), -1))+crossprod(tail(t(orig), -1)))/2  *delta
V.exact <- GramMatrix(base)

all.equal(V.orig, V.exact)

```

That should be within numerical tolerance for a numerical integration. To not compound differences we will use the exact estimate for V.

```{r}
V <- V.exact
V_inverse <- solve(V)
```

Since the integral does depend on data we will need the objects for the integration

```{r}
data(ARC_data, package = 'ARCdata')
object <- 
fitted.trt.sim <-
    fit_PCORI_within_group_model(
        group.data = filter(ARC_data, Trt=='home_visits'),
        outcome_modeler = PCORI_sim_outcome_modeler,
        id.var = elig_pid,
        outcome.var = Asthma_control,
        time.var = time,
        End = 830
    )
```

## Expected Value

The below code is extracted from the implementation at the time of writing from the `predict.PCORI_within_group_model`.

```{r}
resolution <- 400

expected_value <- \(data, ...){
    matrix(
        object$outcome_model |> 
            pcori_conditional_means(..., new.data = data) |> 
            pull('E_Y_past'),
        nrow = nrow(data)
    )}
```

```{r}

data <- object$outcome_model$data
dim(data)

expected.values.old <- 
    pcori_conditional_means(object$outcome_model, new.data = data, alpha=alpha)

beta  <- coef(object$outcome_model)
X     <- model.matrix(object$outcome_model)
Y     <- object$outcome_model |> model.frame() |> model.response()
bw    <- object$outcome_model$bandwidth
kappa <- K2_Biweight_kernel

dim(X)
NROW(Y)

Xbeta <- X %*% beta
dim(Xbeta)

deltaXBeta <- outer(Xbeta[,1], Xbeta[,1], `-`)

Kmat <- deltaXBeta |> 
        K2_Biweight_kernel(bw) 

if(F){
    dim(Kmat)
    max(Kmat) == K2_Biweight_kernel(0, bw)


    K2_Biweight_kernel(0,1)
    K2_Biweight_kernel(-0.5,1)
    K2_Biweight_kernel( 0.5,1)

    local({
        x <- seq(-1.5, 1.5, length.out=101)
        y <- K2_Biweight_kernel(x, 1)
        plot(x, y, type = 'l')
        
    })    
    
    
    denoms = colSums(Kmat)
    
    crossprod(Kmat, Y )/denoms
    
    new_E_exp_alphaY = crossprod(Kmat, exp(-0.3 * Y))/denoms
    new_E_Yexp_alphaY = crossprod(Kmat, Y*exp(-0.3 * Y))/denoms
    
    expected.values.old |> 
        filter(alpha == -0.3) |> 
        transmute(
            elig_pid, time, Y = Asthma_control, 
            E_Y_past, new_E_Y = new_E_Yexp_alphaY/new_E_exp_alphaY,
            E_exp_alphaY, new_E_exp_alphaY = new_E_exp_alphaY,
            E_Yexp_alphaY, new_E_Yexp_alphaY = new_E_Yexp_alphaY
        )
}


expected.values.new <- purrr::map_dfr(alpha, function(α){
    numerators_YexpY  <- crossprod(Kmat, Y * exp(α * Y))
    numerators_expY   <- crossprod(Kmat,     exp(α * Y))
    
    denominators <- colSums(Kmat)
    
    tibble(
        alpha=α, data,
        "E[Y(t)]" = numerators_YexpY/numerators_expY,
        "E[exp(αY(t))]" = numerators_expY/denominators,
        "E[y(t)exp(αY(t))]" = numerators_YexpY/denominators
   )
})


(joined.old.and.new <- expected.values.new |> 
    dplyr::full_join(
        expected.values.old |> 
            select(elig_pid, time, alpha, E_Y_past, E_exp_alphaY, E_Yexp_alphaY),
        join_by(elig_pid, time, alpha)
    ) |> 
    transmute(
        elig_pid, time, alpha, Y=Asthma_control,
        E_Y_past, `E[Y(t)]`,
        "estimates_diff" = abs(E_Y_past-`E[Y(t)]`), 
        E_exp_alphaY, `E[exp(αY(t))]`, 
        E_Yexp_alphaY, `E[y(t)exp(αY(t))]`
    )
)

joined.old.and.new |> filter(log10(estimates_diff) >-10)

```

## Numerical Approximation

```{r}
impute_patient_df <- function(eval.times, df_i, object, right=TRUE){
    outcomes <- pull(df_i, !!(object$variables$outcome))
    
    time_mean <- object$outcome_model_centering[[1]]
    time_sd   <- object$outcome_model_centering[[2]]
    Δ_time_mean <- object$outcome_model_centering[[3]]
    Δ_time_sd   <- object$outcome_model_centering[[4]]

    tibble(
        time = eval.times,
        period = as.numeric(cut(eval.times, c(pull(df_i, !!object$variables$time), Inf), right = right)),
    ) |>
    mutate(
        delta_time := time - df_i$time[period],
        norm_time = (time - time_mean)/time_sd,
        norm_delta_time = (delta_time - Δ_time_mean)/Δ_time_sd,
        prev_outcome = (!!outcomes)[period],
        outcome = 0
    ) |>
    dplyr::rename(
        any_of(
            rlang::set_names(
                names(object$variables), 
                sapply(object$variables, deparse)
            )
        )
    )
}

estimate_influence_term_2 <-
function(
    object, expected_value, alpha, base, a, b, resolution, 
    ...,
    new.data = object$data
){
    if(F){
        resolution <- 1e5
        
        df_i <- object$data |> 
            filter(elig_pid == head(elig_pid, 1))
        test <- for_one(df_i)    
    }

    eval.times <- seq(a,b,length.out=resolution)
    # B <- sapply(eval.times, spline_fn, knots=knots) %>% t()
    B <- evaluate(base, eval.times)
    V_inverse <- solve(GramMatrix(base))

    time_mean <- object$outcome_model_centering[[1]]
    time_sd   <- object$outcome_model_centering[[2]]
    Δ_time_mean <- object$outcome_model_centering[[3]]
    Δ_time_sd   <- object$outcome_model_centering[[4]]
 
    for_one <- function(df_i, ...){
        outcomes <- c( pull(df_i, !!(object$variables$prev_outcome)),
                       pull(df_i, tail(!!(object$variables$outcome),1)))

        spline_df_est <- impute_patient_df(eval.times, df_i, object)

        Ey = expected_value(spline_df_est, alpha=alpha)

        summation <- crossprod(B, Ey) -
            crossprod(head(B,1), head(Ey,1))/2 -
            crossprod(tail(B,1), tail(Ey,1))/2
        bin.width <- (b-a)/resolution
        
        return(summation * bin.width)
    }
    

    new.data |> 
        dplyr::group_by(!!object$variables$id) |> 
        dplyr::group_map(for_one)
}
```

```{r}
obase <- orthogonalize(base)
(term2 <- 
    estimate_influence_term_2(
        object, expected_value,
        obase,
        alpha=alpha,
        a = 60,
        b = 460,
        resolution = 1000,
        new.data = object$data |> 
            filter(elig_pid %in% c(19002, 19004, 19006))
    )
)
```

## Exact Computation

The form of the integral of interest comes out to.

$$
V^{-1}B^1(b)\frac{    \sum_{j=1}^N Y_j e^{\alpha Y_j}\kappa(\beta X_j - \beta x_i(b)|h))}{    \sum_{j=1}^N e^{\alpha Y_j}\kappa(\beta X_j - \beta x_i(b)|h))} - V^{-1}B^1(a)\frac{    \sum_{j=1}^N Y_j e^{\alpha Y_j}\kappa(\beta X_j - \beta x_i(a)|h))}{    \sum_{j=1}^N e^{\alpha Y_j}\kappa(\beta X_j - \beta x_i(a)|h))}
$$

Where $B^1(t) = \int_a^t B(t^\star) dt^\star$. and note that $V=\int_a^b B(t) dt = B^1(b)$. So this expression can further reduce to simply: $$
\frac{    \sum_{j=1}^N Y_j e^{\alpha Y_j}\kappa(X_j\beta - x_i(b)\beta|h))}{    \sum_{j=1}^N e^{\alpha Y_j}\kappa(\beta X_j - \beta x_i(b)|h))}
$$

```{r}
K2_Biweight_kernel <- function(x, h){15/16*(1-(x/h)^2)^2 * (abs(x) <= h)}
```

```{r}
compute_influence_term2_integrals <- 
function(
    object, 
    base, 
    ...,
    kappa = K2_Biweight_kernel,
    bandwidth = object$outcome_model$bandwidth
){

    
    kappa = match.fun(kappa)    
    base1 <- integrate(base)
    V_inverse <- solve(GramMatrix(base))
    
    a <- min(base@knots)
    b <- max(base@knots)
    
    time_mean <- object$outcome_model_centering[[1]]
    time_sd   <- object$outcome_model_centering[[2]]
    Δ_time_mean <- object$outcome_model_centering[[3]]
    Δ_time_sd   <- object$outcome_model_centering[[4]]
    
    data <- object$data
    
    
    
    if(F){
        x_i_b <- data |> 
            filter(
                !!(object$variables$id) == head(!!(object$variables$id), 1)) |> 
            filter(!!(object$variables$time) < max(base@knots)) |> 
            tail(1) |> 
            dplyr::transmute(
                delta_time = !!b - !!object$variables$time,
                norm_time = (!!b - time_mean)/time_sd,
                norm_delta_time = ((!!b - !!object$variables$time) - Δ_time_mean)/
                                  Δ_time_sd,
                prev_outcome = !!object$variables$outcome,
                outcome = 0
            ) |>
            dplyr::rename(
                any_of(rlang::set_names(names(object$variables), 
                                        sapply(object$variables, deparse)))
            ) |> 
            model.matrix(object$outcome_model, data=_)
    }
    beta <- coef(object$outcome_model)
    
    data_b <- data |> 
        dplyr::group_by(!!(object$variables$id)) |> 
        dplyr::group_modify(function(data,...){
            data |> 
            filter(!!(object$variables$time) < max(base@knots)) |> 
            tail(1) |> 
            dplyr::transmute(
                delta_time = !!b - !!object$variables$time,
                norm_time = (!!b - time_mean)/time_sd,
                norm_delta_time = 
                        ((!!b - !!object$variables$time) - Δ_time_mean)/
                        Δ_time_sd,
                prev_outcome = !!object$variables$outcome,
                outcome = 0
            ) 
        }, .keep = TRUE) |>
        mutate(time = !!b) |> 
        dplyr::rename(
            any_of(rlang::set_names(names(object$variables), 
                                    sapply(object$variables, deparse)))
        ) |> 
        ungroup()
    
    X_b <- data_b |> 
        model.matrix(object$outcome_model, data=_)
    X_b_beta <- X_b %*% beta
        
    Y <- model.response(model.frame(object$outcome_model))
    X <- model.matrix(object$outcome_model)
    Xbeta <- X %*% beta

    
    
    KDxb <-
    tmp <- kappa(
        outer(
            Xbeta[,1, drop=TRUE], 
            X_b_beta[,1, drop=TRUE], 
            `-`
        ), 
        object$outcome_model$bandwidth
    )
    
    purrr::map_dfr(alpha, function(α){
        data_b |> 
        mutate(
            time = !!b,
            alpha = α, 
            sum_Y_exp_alpha_Y = crossprod(KDxb, Y * exp(α * Y)),
            sum_exp_alpha_Y = crossprod(KDxb, exp(α * Y)),
        ) |> 
            mutate(influence_term2_integral = sum_Y_exp_alpha_Y/sum_exp_alpha_Y)
    })
}
```

## Special case of numerical integration

$$
\int_{t=a}^b V^{-1}B(t)\hat{E}[Y(t)|\bar{O}(t)_i]dt
$$

This section will test the case for the numerical integration with the special case that the expected value is identically 1. Which should reduce to an vector of length $p$.

```{r}
special.case.1 <- 
    estimate_influence_term_2(
        object, 
        expected_value = 
        function(data, alpha, ...){
            matrix(rep(1, nrow(data) * length(alpha)), nrow(data), length(alpha))
        }, 
        base = base, 
        alpha, a, b, 1e5)
```

```{r}
head(special.case.1)
```

# Another Approach

Investigate the piece-wise linearity or quadratic nature to speed up integration.

```{r}
object$data |> 
    filter(time >= a, time <= b) |> select(time) |> distinct() |> 
    arrange(time) |> 
    mutate(diff = time - lag(time, 1, a)) |> 
    arrange(desc(diff))

# object$data |> filter(time == 68)
```

If $\hat E(Y|\bar O_i(t), t_l < t \leq t+{l+1}) \approx C_0 + C_1 t$ Then

$$
\begin{array}{rcl}
\int_{t_l}^{t_{l+1}} B_\perp(t) \hat E(Y|\bar O_i(t)) &\approx& 
    \int_{t_l}^{t_{l+1}} B_\perp(t) \left(C_0 + C_1 t\right)dt\\
&=& \int_{a}^{t_{l+1}} B_\perp(t) \left(C_0 + C_1 t\right)dt - \int_{a}^{t_{l}} B_\perp(t) \left(C_0 + C_1 t\right)\\
&=& B_\perp^1(t_{l+1})\left(C_0 + C_1 t_{l+1}\right) - \int_{a}^{t_{l+1}} C_1  B_\perp^1(t)dt
  - B_\perp^1(t_{l  })\left(C_0 + C_1 t_{l  }\right) + \int_{a}^{t_{l}} C_1  B_\perp^1(t)dt
\\
&=& B_\perp^1(t_{l+1})\left(C_0 + C_1 t_{l+1}\right) - B_\perp^1(t_{l  })\left(C_0 + C_1 t_{l  }\right)
  - C_1 B_\perp^2(t_{l+1}) + C_1 B_\perp^2(t_{l})
\\
&=& \left[B_\perp^1(t)\left(C_0 + C_1 t\right) - C_1 B_\perp^2(t))\right]_{t_l}^{t_{l+1}}
\end{array}
$$ with $B_\perp^1(t) = \int_a^t B_\perp(t^\prime) dt^\prime$ and $B_\perp^2(t) = \int_a^t B_\perp^1(t^\prime) dt^\prime$.

$$
\left[B_\perp^1(t)\left(C_0 + C_1 t\right) - C_1 B_\perp^2(t)dt\right]_{t_l}^{t_{l+1}} = 
B_\perp^1(t_{l+1})\left(C_0 + C_1 t_{l+1}\right) - C_1 B_\perp^2(t_{l+1}) -
B_\perp^1(t_{l})\left(C_0 + C_1 t_{l}\right) + C_1 B_\perp^2(t_{l})
$$ $$
C_1 = \frac{\lim_{t\to t_l^-}\hat E(Y|\bar O_i(t_{l+1}))-\hat E(Y|\bar O_i(t_{l}))}{t_{l+1}-t_l}
$$ $$
C_0 = \hat E(Y|\bar O_i(t_{l+1})) - C_1 t_{l+1}
$$

for one case

```{r}
    df_i <- object$data |> filter(elig_pid == 19002)

    a <- min(base@knots)
    b <- max(base@knots)
    obase <- orthogonalize(base)
    
    B1 <- integrate(obase)
    B2 <- integrate(B1)

    
    patient.df <- df_i |> 
        filter(
            !!a <= !!object$variables$time,
            !!object$variables$time <= !!b
        )

    times <- c(a, pull(patient.df, object$variables$time), b)
    
    left <- impute_patient_df(head(times, -1), df_i, object, right = FALSE) |> expected_value(alpha)
    right <- impute_patient_df(tail(times, -1), df_i, object) |> expected_value(alpha)
        
    dt <- diff(times)
    
    C1 = (right-left)/dt
    C0 = right-C1*tail(times, -1)
    if(F){
        
        geom_abline(data=tibble(
            c0 = C0[,2],
            c1 = C1[,2],
            period = factor(seq.int(nrow(C1)))
        ), aes(slope=c1, intercept=c0, col=period, group=period))
        
        library(ggplot2)
        
        
    }
    
    # eB1 <- evaluate(B1, times)
    # eB2 <- evaluate(B2, times)
    
    map(seq_along(alpha), function(i){
        pmap(
            list(
                c0 = C0[,i],
                c1 = C1[,i],
                t1 = head(times, -1),
                t2 = tail(times, -1)
            ),
            function(c0, c1, t1, t2){
                (c0+c1*t2)*evaluate(B1,t2) - (c0+c1*t1)*evaluate(B1,t1) -
                c1*(evaluate(B2, t2) - evaluate(B2, t1))
            }) |> reduce(`+`)
    })
```

```{r}
tmp <- 
    impute_patient_df(a:b, df_i, object) %>% 
        mutate(., alpha = 0, Ey = expected_value(., alpha=0)[,1])
library(ggplot2)
ggplot(data=tmp |> mutate(across(period, as.factor))
       , aes(x=time, y=Ey, col=period, group=period)) + 
    geom_line() +
    geom_point(data=tibble(
        time = head(times, -1),
        Ey = left[,2],
        period = factor(seq.int(1:4))
    ), shape =0) + 
    geom_point(data=tibble(
        time = tail(times, -1),
        Ey = right[,2],
        period = factor(seq.int(1:4))
    ), shape =1) +
    geom_abline(data=tibble(
        c0 = C0[,2],
        c1 = C1[,2],
        period = factor(seq.int(nrow(C1)))
    ), mapping = aes(slope=c1, intercept=c0, col=period, group=period))




```

numerically integrate again

```{r}
B <- evaluate(obase, a:b)
crossprod(B, tmp$Ey)
```

```{r}
plot(obase)
plot(B1)
plot(B2)
```

as a function

```{r}
compute_influence_term_2_linearly <- function(df_i, alpha, object, base){
    a <- min(base@knots)
    b <- max(base@knots)
    obase <- orthogonalize(base)
    
    B1 <- integrate(obase)
    B2 <- integrate(B1)

    
    patient.df <- df_i |> 
        filter(
            !!a <= !!object$variables$time,
            !!object$variables$time <= !!b
        )

    times <- c(a, pull(patient.df, object$variables$time), b)
    
    left <- impute_patient_df(head(times, -1), df_i, object, right = FALSE) |> expected_value(alpha)
    right <- impute_patient_df(tail(times, -1), df_i, object) |> expected_value(alpha)
        
    dt <- diff(times)
    
    C1 = (right-left)/dt
    C0 = right-C1*tail(times, -1)
    if(F){
        
        geom_abline(data=tibble(
            c0 = C0[,2],
            c1 = C1[,2],
            period = factor(seq.int(nrow(C1)))
        ), aes(slope=c1, intercept=c0, col=period, group=period))
        
        library(ggplot2)
        
        
    }
    
    eB1 <- evaluate(B1, times)
    eB2 <- evaluate(B2, times)
    
    influence_term_2 <- map(seq_along(alpha), function(i){
        pmap(
            list(
                c0 = C0[,i],
                c1 = C1[,i],
                t1 = head(times, -1),
                t2 = tail(times, -1)
            ),
            function(c0, c1, t1, t2){
                (c0+c1*t2)*evaluate(B1,t2) - (c0+c1*t1)*evaluate(B1,t1) -
                c1*(evaluate(B2, t2) - evaluate(B2, t1))
            }) |> reduce(`+`)
    })
    
    tibble(alpha, influence_term_2)
}
```

```{r}
compute_influence_term_2_linearly(df_i, alpha, object, base) |> 
    pull(influence_term_2) |> reduce(rbind) |> t()
term2[[1]]
```

## investigating linearity based on bandwidth

```{r}
plot_by_bandwidth <- function(bandwidth){
    eval.points <- a:b
    alpha = c(-0.3, 0, 0.3)
    
    Ey <- impute_patient_df(eval.points, df_i, object, right = FALSE) |> 
        expected_value(bandwidth = bandwidth, alpha = alpha)
    
    tmp <- tibble(
        time=rep(eval.points, length(alpha)), 
        alpha = rep(alpha, each = length(eval.points)), 
        Ey = as.vector(Ey)
    )
    
    
    ggplot(data=tmp, aes(x=time, y=Ey, group=alpha, col=alpha)) + 
        geom_line()
}
```

```{r}
plot_by_bandwidth(5)
plot_by_bandwidth(30)
plot_by_bandwidth(100)
```
